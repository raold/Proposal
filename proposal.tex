\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage{timeline}
\usepackage{cite}
\usepackage[hang,small,bf]{caption}
\usepackage{booktabs}
\usepackage{chngpage}
\usepackage{layouts}
\usepackage{enumerate}
\usepackage{hyperref}%need to maker hyperlinks
\usepackage[toc,page,titletoc,header,title]{appendix}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}
%\newcommand*{\marginnoteleftadjust}{1}
\usepackage{textcomp}
\bibliographystyle{unsrt}

\begin{document}

\title{Master's thesis proposal [rev\_4.5]} %textwidth: \printinunitsof{cm}\prntlen{\textwidth}}
\author{\normalsize Richard Oldham, DDS \vspace{7pt} \\ 
		\small University of Pittsburgh \vspace{-2pt} \\
		\small Department of Biomedical Informatics}
\maketitle

\begin{abstract}
The benefits of Computerized Patient Records (CPRs) are well documented. Yet current dental CPRs inadequately support chairside use as evinced in low adoption rates for operatory computers. If dental professionals have any hope of realizing the advantages CPRs offer, information systems must adapt to their workflow and not \textit{vice versa}. To that end, research suggests tablet devices hold promise as an alternative to traditional desktop PCs' ergonomic shortcomings in the clinical environment. Designing a goal and task specific tablet-based treatment planning interface may help bridge the adoption gap between office and chairside computer use in dentistry. Evaluation can determine if users are faster, more successful, less error prone, or more subjectively satisfied with the tablet application over traditional CPRs.
\end{abstract}

\setcounter{tocdepth}{4}
\tableofcontents
\listoftables
\newpage

\section{Background}
First, I summarize applicable findings from usability and informatics research. Next, I discuss a user model for treatment planning in dentistry. Lastly, I discuss conclusions and potential solutions.

\subsection{Adoption Gap}

The adoption of Computerized Patient Records (CPRs) by healthcare professionals has long been recognized as a key step in improving patient care\cite{Chasteen1992A-computer-data,Eisne1993The-computer-ba,Thompson2004The-Decade-of-H,Spicer2008Bytes-and-bites,Schleyer2011Advancing-oral}. Dentists recognized the power of computers assisting with practice administration --- such as scheduling and billing --- becoming early adopters of computers in-office (Figure \ref{adoption}).

\begin{figure}[h!]
\begin{center}
\includegraphics[width=105mm]{comp.png}
\end{center}
\caption{Year of first computer installation for office and chairside use by US dentists\cite{Schleyer2006Clinical-Comput}. The red bar represents completely paperless practices.}
\label{adoption}
\end{figure} 
\newpage

\noindent Survey data from 2010, the most recent available, reported 92\% of respondents using Practice Management Software (PMS)\cite{Levine2010}.\footnote[2]{Here I use PMS to refer to software that handles office administration whereas a CPR handles patients' clinical data. Most CPR software is also PMS but not the other way around.} However, the conclusions of two usability studies on four dental CPRs, which together comprise more than a 70\% market share for such systems, suggest poor usability is a barrier to dental CPR adoption for chairside use\cite{Thyvalikakath2007Heuristic-evalu,Thyvalikakath2008A-usability-eva}. The gap between office adoption of computers and the adoption of computers for chairside use is evident in Figure \ref{adoption}.

\subsection{Usability}
The first of the two cited usability studies employed heuristic evaluation methods\cite{Nielsen1994Usability-Inspe, Schleyer:2007fk}. Three expert reviewers examined each of the four CPRs and tabulated violations of Nielsen's heuristics \cite{Thyvalikakath:2009fk}. Evaluators found 229 violations in total across EagleSoft, Dentrix, PracticeWorks, and SoftDent. Consistency and Standards, Match Between System and the Real World (\ref{controls}), and Error Prevention were the most commonly violated heuristics  with the distribution of violations roughly equal among the four CPRs inspected. The authors admit their conclusions offered no comparative assessment between the CPRs but the magnitude of violations suggested significant room for usability improvement.

The second usability study compared\cite{Nielsen1994Enhancing-the-e} these same market-leading CPRs by assigning common tasks to five novice users for each of the four systems ($n = 20$). Users were purposively sampled with four full-time dental faculty members, eight practicing dentists, and eight senior dental students from the University of Pittsburgh School of Dental Medicine comprising subjects for the assessment. Two experts coded task completion success and associated usability problems. The authors used Wilcoxon rank-sum tests, Spearman correlation coefficient tests, and Kruskal-Wallis tests to determine the correlation between usability problems and task outcomes. The frequency of observed usability problems correlated positively with the frequency of task failures for all tasks except two $(p < 0.05)$: assigning a tooth as missing and recording soft tissue measurements. On average, users correctly completed 43\% of the assigned tasks leading to a similar conclusion: the most commonly used dental CPRs suffered from a steep learning curve and have ample room for usability improvement.

The results of these two studies point to inadequate support for chairside use. All four systems included in these studies began life as PMS with clinical functions added later. The abundance of nested menus, tree selections, and drop down lists for clinical and non-clinical functions alike are evidence of this (\ref{dentrixplain}). Dentrix, for instance, provides sometimes two or three different input methods for the same function on the same screen (button on a pallet, tree selection, and drop down menu). All four systems evaluated by Thyvalikakath et al. employ screen designs that include nearly all input options at once rather than the options needed for the specific task or goal (\ref{ES}). Interfaces with many options can make finding the function of interest more difficult, increase cognitive load, and slow the user\cite{Qian2011Towards-develop}. One could argue complicated interfaces are not universally poor if such an interface is appropriate for the job (for example, an airplane cockpit). But given the evidence, it seems the gulf of execution and evaluation \cite{Norman:1989uq} in dental CPRs is unnecessarily wide. Dentrix and Eaglesoft screen design, for example, confused novice users with intermixed controls for entering existing conditions and planned procedures on the same palette. And performing basic tasks, such as marking a tooth as missing, require four to six mouse clicks across a wide swath of screen real estate (\ref{dentrixusabil}). 

Fitts's law \cite{Fitts:1964vn,Fitts:2012kx} predicts the average task completion time, $T$, as primarily a function of $D$, the distance from the starting point to the center of the target and $W$, the width of the target measured along the axis of motion such that $ T = a + b \log_2 \left(1 + \frac{D}{W}\right) $ where $a$ and $b$ are experimentally determined constants. Though not measured by Thyvalikakath et al. (2008), one might expect poor task completion time for the surveyed CPRs in light of mousetracking data that illustrated long distances and narrow targets (\ref{dentrixusabil}). Compounded over the course of an initial exam appointment, this method of data input is time prohibitive for a single user. Meaning, these input design choices are far from efficient for a user that requires efficiency.

Since the information input and retrieval processes were not integrated into the concepts of tasks and workflow, users were required to divide their attention between navigation and task completion. In both usability studies, the authors noted information that would typically appear on a single paper form was spread out over two or more screens in the CPR. The comparative evaluation cited difficulty with tasks that required screen switching as a principle source of user frustration. Evidence suggests these problems are not unique to dental health information technology (HIT) applications\cite{Ash2004Some-unintended,Rose2005Using-qualitati}.

Readers of these two usability studies offered valid criticisms\cite{Cockerell:2009fk}. One such critique centered on the authors' choice of novice users for the evaluation. Critics pointed to the low likelihood of a user being completely unfamiliar with the CPR in a live office setting. Training office staff to use the CPR is routine and thus the steep learning curve cited in the conclusion may not reflect the learning curve faced by actual users. Another critique, from the same citation, questioned the assumption of causality between poor usability and low adoption rates of CPRs by dentists. The author sees private practice dentists' primary concern as one of return on their investment in Information Technology over potential usability issues discovered post purchase. Regarding heuristic evaluation, Nielson and Molich (1990) developed this discount inspection method at a time when it was expensive to gain access to users. Nielson and Molich warn readers of haphazard application of their method and the need for training expert reviewers and ... Heuristic inspection can only determine the extent to which an interface adheres to a set of best practices; to make broader claims about generalizability of results would be problematic.

\subsection{Attitudes and Use}
In a telephone survey of 102 general dentists in the United States, researchers discovered two main sources of user frustration in using dental CPRs: steep learning curves and difficulty entering clinical data\cite{Schleyer2006Clinical-Comput}. Respondents considered `better input methods,' `smaller computers,' and `better user interface design' as principal areas for improvement. Another important concern included lack of infection control inherent with traditional keyboard and mouse input. These responses track closely with those elicited from British users through a similar survey\cite{John2003Questionnaire-s}.

Dental practices use their computers primarily for scheduling patients and tracking completed procedures (Figure \ref{use}).\label{fig:4}
\begin{figure}[h]
\begin{center}
\includegraphics[width=\textwidth]{papervscomp.jpg}
\end{center}
\caption{Storage of major clinical information categories on paper/computer, sorted by utilization of computer-based storage in descending order\cite{Schleyer2007A-Qualitative-I}.}
\label{use}
\end{figure}
\\ Because dental CPRs are poorly designed for chairside use, some users accommodate by working around the CPR. Some practices record temporary notes on a patient napkin or tray cover and commit these notes to the electronic record later while others record histories on paper and treatments on the computer. While transcribing notes from paper to the computer is not an inherent problem, such a practice has the potential for error. Storing some information in paper format and some in electronic format (Figure \ref{use}), similarly, is not \emph{prima facie} poor practice but requires the consumer of the information to switch between the paper-based and computer-based records. Fragmentation of data into multiple locations has one inevitable drawback: switching requires cognitive overhead and time. This burden can slow the consumption of information by the clinician or produce transcription errors\cite{Salvucci2009Toward-a-unifie}. The need to work around the CPR is due, in some part, to the difficulty of integrating the necessary hardware into an already cramped dental operatory\cite{Schleyer2004Why-integration,Unthank2004Designing-your-} and, in some part, to the time-prohibitive cost of entering data into a poorly designed system. The ergonomics of one dentist, one assistant, and one patient gathering, entering, retrieving, and presenting information are complex (\ref{physical}). The suggested areas of improvement noted in the Schleyer, et al. (2006) survey highlight the frustration of using software designed without these ergonomics in mind. The task of finding the required information inside the patient record is often criticized as time-intensive and distracting\cite{Nygren1998Helping-clinici}. This is especially concerning given the increased information needs of clinicians in an increasingly time-pressured environment. If we accept the premise that HIT can improve patient care, and there exists a large adoption gap, the necessity of generating and understanding a user model becomes apparent.

\subsection{User Model}
Recognizing the interplay between usability, practice culture, and operatory configuration, researchers set out to model the workflow of an initial examination and treatment planning appointment through contextual inquiry\cite{Irwin2009A-preliminary-m}. During this appointment the dentist documents the patients current condition, the patient-specific goal for oral health, and generates a sequenced plan to proceed from present state to the goal state. This process, with its findings, diagnoses, and resulting plan, must then be discussed with the patient. Depending on the complexity of problems, multiple treatment plans may be required. Of any appointment, this one generates the most clinical artifacts such as radiographs, photographs, hard and soft tissue diagnostic charting,  and study models. It follows that the initial exam requires the most data input of these artifacts into the CPR. And artifacts must be quickly retrieved for consumption by the clinician and for discussion with the patient. Following the initial visit and generation of a treatment plan, each subsequent visit requires comparatively little interaction with the CPR. The dentist may check the medical history or reference the planned procedures, for example. Thus the initial appointment requires the most interaction with the CPR for data entry and retrieval, making it an ideal candidate for study.

A thorough initial exam and treatment planning appointment is vital for not only diagnosing every present condition but communicating the condition, its consequences, and treatment options as well. Generating a treatment plan is analogous to peeling an onion: the dentist starts with the most obvious signs and symptoms and continues examination, testing, and imaging until all signs and symptoms have been mapped to a problem list. The dentist may ascribe diagnoses to items on the problem list and then generate a treatment to address each item. This process is non-deterministic, across patients and dentists, and time-intensive, often requiring two people. Typically one operator will diagnose and call out findings while an auxiliary transcribes the findings into the computerized record. While this task may be handled differently in sequence from one dentist or patient to another, the steps are the same and mappable to common set of terms and abstractions. 

Irwin, et al. (2009) observed an auxiliary may not always be available and dental team members used a variety of workarounds in such a situation. For example, hygienists often perform recare examinations without an assistant, noting their preliminary findings on a piece of paper prior to discussion with the dentist. Some clinicians postpone any data entry tasks to a time after the patient has been dismissed. This presents the problem of having to remember what was done and why. Even under ideal circumstances, that is, when an assistant was present, over 60\% of the Irwin's observed breakdowns were due to technology. One implicit conclusion from the Irwin model was dentists spend little time entering data with the majority of CPR interaction handled by hygienists and assistants. Schleyer, et al. (2006) reported dentists participating in only 23\% of data entry tasks, chief among them being progress notes. Hygienists and assistants handled most other data entry tasks such as diagnoses, oral health status, and histories. Given the larger turnover of non-dentist staff, and the fact non-dentists perform about 75\% of data input, learnability of a CPR becomes an important concern. Whether dentists would employ more clinical functions in their CPR given improved interfaces, as Irwin, et al (2009) described, ``with the flexibility in sequencing, granularity and comprehensiveness'' for data entry remains to be seen. But Irwin conclusions mirror the conclusions from the Schleyer et al. 2006 survey: CPR design must accommodate to the demands of dental workflow.

\subsection{Conclusions and Solutions}
Several important conclusions can be gleaned from the cited literature. First, dental operatories are small and require careful planning to integrate the CPR's supporting hardware. The suggestion of using smaller computers from the Schleyer, et al. (2006) survey reveals user frustration with this integration burden. Next, the current paradigm in dental CPR design and ergonomics requires an auxiliary for efficient data entry. Most dentists are consumers of patient information while hygienists and assistants perform most data entry. Following the generation of a treatment plan, subsequent appointments require comparatively little data entry or retrieval. Given the results of the user model study, the highest value targets for CPR improvement are the functions used during the initial visit: namely, diagnoses and treatment planning.

Schleyer et al. (2006, 2007) and Irwin et al. (2009) report the common practice of using multiple or duplicate data entry. A user may write something on paper, such as routing slips or preliminary findings, later transcribing this information into the electronic record. Alternatively, one might record the medical history on paper and use the CPR to record planned and completed treatments. This is due, in part, to the fact that dental CPRs cannot capture the variety of data with the flexibility of paper forms\cite{Schleyer2007A-Qualitative-I}. Depending on the survey of paper forms and the CPR used for comparison, CPRs can lack  80--90\% of the data elements contained in paper records. Duplicate data entry might also be used to accommodate the non-linear and variable process by which patients are escorted through this initial visit. Therefore, an alternative system needs to allow the user a temporary and mutable data store to enter information before committing the entry to the record. And the clinical vocabulary of the information system must be at least as large as that of the clinician. Efforts are underway to enumerate and control this vocabulary \cite{Kalenderian:2011ly,White:2011zr,Acharya2009Electronic-dent,Emmott2010Electronic-dent} but providing the most commonly used data elements and allowing the user to customize the type and sequence of information capture may suffice.

Little research effort has been dedicated to studying mobile devices in dentistry. While many dental-specific mobile applications exist and several vendors are exploring mobile platforms, most literature are case reports. For over a decade, dental clinicians have recognized the potential for hand-held computing devices to address the limitations of traditional PCs\cite{Taylor2002Handheld-comput,Jablow2003Your-practice-i}. Coupling the advantages of mature tablet devices with a novel interface, which incorporates lessons learned though previous research, may hold promise.


\section{Tablets and Usability}
Tablets offer several advantages over traditional desktop PCs in clinical use. Because CPR access is not universally available in medical exam rooms, tablets' smaller size and portability were central to their adoption by physicians. Tablets allow the clinician to enter orders, notes, and review information while remaining mobile. Similarly, tablets' smaller footprint and portability could address the ergonomic challenges in dental practice. A tablet is ideal for consuming information, which is the principle concern of the clinician. Tablets can at least match the traditional desktop PC in data entry speed and accuracy with use\cite{Kirby1996The-PEN--PAD-da,Mackenzi2002Text-entry-for-}. They can be easily shared between the provider and patient and easily disinfected\cite{Mayrhofer2007Pen-based-Elect}. Properly designed touch-screen mobile interfaces have demonstrated promise in a variety of medical settings\cite{Haller2009Handheld-vs.-la,Mulligen1998Clinical-data-e,Baumgart2005Personal-digita,Lu2005A-review-and-a-,Seneviratne2010Improving-stylu}. Finally, if users are as capable on a mobile device as a traditional PC, the ergonomic and portability advantages can increase user subjective satisfaction with a mobile system over a conventional desktop\cite{Cole2006A-comparative-s}.

Tablets make ideal devices for which to design interfaces for fast task completion time. Because their screen size is small and users make input choices with their fingers, buttons must be large. Most tablet devices will not discriminate capacitive touch with less than 8--9mm surface area. Further, because tablet screen real estate is limited, one must carefully consider the interface elements and sequence of interactions. This economy of choice requires a tablet-based interface to be well adapted to user tasks and goals. Thus, given a larger button size on a smaller screen, Fitts's law would suggest tablets as a logical platform choice.

Some remain skeptical of the virtues of tablet computers in clinical use\cite{Kaneshige2011iPad-in-Healthc,Mashman:2011uq} and, compared to the medical literature, few investigators have studied tablet use by the dental team\cite{Frank2010IPad--tool-or-t}. Applying the insights from medical informatics research to dental problems presumes exchangeability of the domains. This may not be the case (Table 1).
\begin{table}[!t]
	\caption{Summary comparison of differences across medicinal and dental domains.}
	\begin{center}
	\ra{1.3}
\begin{tabular}{l  l  l}
\toprule
\makebox[0.32\textwidth][r]{\textbf{Feature of practice}} & \makebox[0.3\textwidth][r]{\textbf{Domain}}  \\
\cmidrule{2-3}	& \textit{Dentistry}  &  \textit{Medicine} \\ 
\midrule
Patient status  &  Usually not sick  &  Usually sick  \\
No. of encounters per day	&  Few	  &  Many          \\
Average visit length	  &  Long 	&  Short   \\
No. of diagnoses  &  Few	  &  Many                      \\
No. of therapies per diagnoses	&	Many 	&  Few       \\
No. of initial visit artifacts	&	Many 	&  Few       \\
\bottomrule
\end{tabular} \end{center} \end{table}
A key difference to note is the small number of diagnoses in dentistry compared to medicine; dentists cover a smaller portion of the body compared to physicians. But for each diagnoses there are a larger number of choices for treatment. One might explain this difference by pointing to the larger role patient preferences play in dental treatment planning\cite{Kay1992Restorative-tre} or the smaller role of evidence-based practice in dentistry compared to medicine\cite{Tellez-2011-Sealants}. Another key difference is ergonomic: physicians stand or sit bedside while the dental ergonomic is unique. Because dental patients are usually less sick, the tablet interface needs fewer input controls. And because the number of diagnoses is small and therapies per diagnoses large, several rule-based functions could help generate treatments from problems saving time. Given the success enjoyed by tablets in complex medical settings, I remain optimistic about tablet performance in the dental operatory. Creating a usable and useful interface for the tablet is a separate consideration.

Regarding screen design, Thyvalikakath, et al. (2008) recognized the disconnect between task flow and screen design in dental CPRs ahead of a formal modeling study. Several topical conclusions the 2008 comparative usability study include: \begin{itemize}
\item Users should be able to identify their treatment preferences and software should support that approach.
\item Data entry and retrieval controls available on screen should correspond with the tasks to be completed. Unrelated or extraneous controls should not be shown. Information that belongs to a specific task context should be shown together or be easily accessible. For instance, hard-tissue and periodontal findings often must be reviewed together to make a clinical decision and should not be separated unnecessarily.
\item Data entry and functional controls should be organized and labeled clearly according to input class (findings, planned/completed procedures, notes, pictures, annotations, etc.).
\end{itemize}

Lastly, the User-Centered Design (UCD) approach to software engineering has demonstrated promise in general\cite{Bannon1986Issues-in-desig,Wixon1997The-usability-e,Gould1997How-to-design-u,Abras2004Encycolopeida-o} and HIT specifically\cite{Johnson2005A-user-centered}. Thyvalikakath, et al. (2007) recognized UCD as a potential solution to the multiple heuristic violations noted during expert review. UCD is a broad term to describe design processes in which end-users influence the software design. Linking the iterative design process to feedback from users has a proven track record of producing highly usable software. I elaborate on the proposed incorporation of the UCD approach in Section \ref{eval}.

\section{Proposed Research}
Based on research evidence, tablet devices make a logical hardware choice. However, hypotheses about tablet use in dentistry remain untested. The extent to which tablet devices and touch interfaces can improve data entry and user satisfaction is a question left to evaluation. But first an interactive tablet-based treatment planning prototype is needed.

Research is currently underway to qualify and quantify the data private practice dentists capture in their CPRs. Given the time constraints of clinical practice and poor usability demonstrated by market-leading CPRs, we hypothesize dentists predominantly document completed procedures and few diagnostic findings (Figure \ref{use}). This is accepted practice by third-party payers in contrast to medicine. Given the lack of open-domain knowledge of type and quantity of data users store, design choices must rely on literature and best practices. But once completed, the data from this study can help inform system design --- ranked list UI elements, for example.

I propose testing two hypotheses: (1) tablet computers, using platform-native UIs, can at least match conventional desktop computers in data entry speed and task completion; (2) users will prefer using a mobile touch screen device over the conventional desktop PC.

\subsection{Treatment Planning Prototype}

To effectively evaluate the comparative usability of tablets and desktop PCs a measure of functional equivalence across the two systems is required. That is to say the tablet prototype must be able to input and retrieve the same clinical artifacts necessary for treatment planning as a mature software system like Dentrix or EagleSoft. Such artifacts include:
\begin{itemize}
\item Patient histories: both medical and dental histories are critical to patient safety and disease management
\item Hard tissue: both existing restorations and conditions that would indicate treatment
\item Soft tissue: periodontal measures such as clinical attachment level, soft tissue margins, and common periodontal findings (e.g. furcation location and classification)
\item Picture Archival and Communication System: radiographs as well as intraoral and extraoral photographs play an increasingly important role in dental practice. Such artifacts provide not only valuable information to the clinician for decision-making but also aid in communicating that information in a patient-friendly manner.
\end{itemize}
These are the same class of items required to work through case examples in the seminal textbook on dental treatment planning by Sefanic and Nesbit\cite{Stefanac2006Treatment-Plann}. Further these artifacts are the same ones used by non-digital dentists (Appendix B) and correspond with the task and user models generated by Irwin et al., thus offering a consensus for high value targets for data input and retrieval. Assuming the four mentioned artifacts are necessary and sufficient to complete a dental treatment plan, and given that such functionality is already present in current CPR vendor offerings, what is the value proposition?

From survey data we know that dental practices value digital functionality related to financial reimbursement. Poor usability demonstrated in evaluation offers a plausible explanation for this and may help explain the practice of keeping some artifacts digital and others on paper. Why would a clinician bother with the many clicks and screen shuffling required to document all of their findings in the digital record if they are paid only for the completed treatments? Indeed many clinicians either use planned treatments as their primary method of documentation or use paper records as a workaround. 

If a system were designed with goals and tasks in mind, however, it is feasible that a small number of rules could unambiguously and programatically render diagnoses from problems---generating knowledge from data and saving the operator valuable chair-time in the process. These rule-based functions are a necessary first step to improving patient care by changing the work flow process from ``what treatment should address the problem?'' to ``why is there pathology present?'' Doing so allows a potentially valuable hook into decision making process with which to provide clinical decision support.

%Many options are available for mobile development. The two dominant operating systems for tablet devices are Android and iOS. To develop a platform-native application, Android requires application coding in Java and iOS requires coding in Objective-C. Alternatively, a web-native application can be ``wrapped'' for use on any platform using responsive web design (a small JavaScript instruction set to resize content based on browser resolution). While each platform has advantages and disadvantages, no design decision has yet been made.

In order for the prototype to be interactive, The functional specification includes:

\begin{itemize}
\item The ability to document the most common diagnostic findings in a clinically linear fashion (find all sites affected with diagnostic condition, move on to the next condition)
\item The ability to automatically generate diagnoses from the documented findings
\item The ability to automatically map a list of treatments, based on provider preferences, from the list of problems and diagnoses
\item The ability to bin and sequence the list of treatments to form one or several treatment plans
\end{itemize}

Following the generation of a treatment plan (or plans), the provider next discusses the findings with the patient. The ability to summarize findings for the providers use in treatment planning is as important as communicating these findings to the patient. Using the treatment plan ``patient view'' to facilitate this discussion could help drive treatment plan acceptance. This feature would undoubtedly be beneficial but may fall outside the scope of this project. The ``patient view'' function is but one example of the many functions available to users once patient data is present in the CPR. However, addressing the problem of cumbersome data entry is a necessary prerequisite to reaping the benefits of computerized records.

\subsection{Evaluation}
\label{eval}

% fractional factorial
% NOT crossover

Dsesigning a novel tablet interface lends itself well to the evaluation process. Were I to evaluate only the interfaces, there would no advantage to use of a smaller device. Subjects could just as easily evaluate the novel interface on a desktop PC alongside a conventional CPR. Therefore, I propose a two stage evaluation using fractional factorial design. For the vector of participants of length $n$, each participant $p$ is tasked with entering one of two comparably difficult patient cases $c_{1,2}$ into the conventional CPR and tablet system. If Bob were tasked with entering $c_1$ into Dentrix, he would then enter $c_2$ into the tablet system. For the next participant, Alice, the case assignment switches. The design is fractional factorial because not every combination of cases and methods will be administered for each subject in order to avoid learning effects from entering the same patient case twice. This experiment design is well suited to comparing the relative efficiency of data entry across the tablet and conventional CPR because of within-subjects comparison. Each user must use both methods of data input and thus acts as their own control when comparing to an alternative. After gathering the data, I can examine the relative impact of case selection, person, and data input method on task completion time and error rate. Significant effort will be made to select two patient cases of equal difficulty and comprehensiveness in order to minimize the case effect on variance of task completion time and error rate.

A second evaluation, using the same design but different setting, can determine the relative ergonomic advantages to a tablet device. Subjects will sit in a dental operatory and receive paper artifacts to enter each system. Using video recording, I can measure subject motion over time and determine the relative efficiency of each device in the physical environment.

\begin{table}[h!b]
\label{evaldesign}
\caption{Proposed two part within-subjects evaluation design using a tablet-based prototype and conventional CPR for comparison}
	\begin{center}
	\ra{1.3}
\begin{tabular*}{\textwidth}{p{1.9cm}p{2cm}p{1.9cm}p{5.1cm}}  
%l  l  l}{|p{1cm}|p{3cm}||l}
\toprule
\textbf{Evaluation} & \textbf{Users} & \textbf{Setting} & \textbf{Design} \\
\midrule
Usability test & Na\"{i}ve with 30 minutes of training & Lab-based & Users sit at a desk in `clean room' enter one task set per system; tests interface with time \vspace{4pt}\\ 

Function study & Na\"{i}ve with 30 minutes of training & Clinical & Users sit in a clinical environment enter one task set per system; tests interface \& ergonomic with time \& motion \\
\bottomrule
\end{tabular*} \end{center}\end{table}

Evaluation of the tablet application requires comparing it to an alternative. Two logical points of comparison are the most popular CPRs in private practice: Dentrix and EagleSoft. Vendors have granted the CDI access to these CPRs and using one of them for the purposes of evaluation should present no challenges.

As previously described, the UCD approach to development is ideally suited to the proposed research. The University of Pittsburgh's Center for Dental Informatics and School of Dental Medicine can provide ready access to potential participants for design feedback ahead of the formal evaluation. This feedback could take the form of expert heuristic inspection or small-scale usability tests. The purpose of this feedback is to confirm the design specification and implementation. Depending on the results of this feedback, one or more rounds of iteration may be necessary.

\subsubsection{Instruments}

\begin{enumerate}[(a)]
\item{\textit{Task completion success}}\\
Logical summative measure for overall usability measured by determination of user completing the task within a specified time range (say 10 minutes), regardless of accuracy of the input.

\item{\textit{Task completion time, if successful}}\\
Useful metric because of quantitative nature allowing statistical modeling of the relative effects of the method, case, and subject on the task completion time. Useful for comparing data input speed as measured with a stop watch by observer.

\item{\textit{Subjective user satisfaction}}\\
One of the only means of measuring user preferences across data input methods. Measured through survey of users with a validated instrument, of which there are many\cite{Chin1998Development-of-, Sittig1999Evaluating-phys, Wixom:2005fk, Han:2004uq,Kettinger:1994vn,Aladwani:2002kx}.

\item{\textit{Error rate}}\\
Also quantitative measure, if secondary to task completion time because users are expected to finish the data input tasks but not expected to commit errors. Useful for gauging effectiveness or quality of user input. Measured through match of paper artifacts to electronic records as determined by observer with domain expertise.
\end{enumerate}




\subsubsection{Power Analysis}

%I am grateful for Dr. Roger Day's expertise and assistance in generating a power analysis. 
Little consensus exists on the appropriate sample size for usability evaluations\cite{Virzi:1992ve,Lewis:1994ly,Turner:2006zr,Nielsen:1993ys}. While some researchers in the HCI domain acknowledge parameter settings for a power analysis are little more than a best guess, we concluded an inspection of the literature and effort towards sample size determination would be worthwhile. The experiment design makes use of quantitative measurements and because of this we can use generalized linear models to simulate the data and determine power accordingly. Thyvalikakath et al. (2008) argue:
\begin{quote}
\small{``We chose five participants per group because this number is considered adequate for usability testing as evidenced in the usability engineering literature\cite{Nielsen1994Enhancing-the-e}.''}
\end{quote}
\noindent Nielsen offers no guidance on sample size in the cited article, however. 

Virzi (1992), Nielsen and Landauer (1993), and Lewis (1994) have published influential articles on the topic of sample size in usability testing. In these articles, the authors presented a mathematical model of problem discovery rates in usability testing. These models used the Poison distribution of rare events to simulate problem discovery rates. The authors determined it was feasible to determine the sample size needed to uncover a given proportion of problems in an interface during one test and presented empirical evidence for the models. Some important claims from these papers:
\begin{itemize}
\item{Most usability problems are detected with the first three to five subjects.}\item{Running additional subjects during the same test is unlikely to reveal new information.}\item{Return on investment (ROI) in usability testing is maximized when testing with small groups using an iterative test-and-design methodology.}
\end{itemize}Nielsen and Landauer (1993) extended Virzi’s (1992) original findings and reported case studies that supported their claims for needing only small samples for usability tests. They and Lewis (1994) identified important assumptions about the use of the formula for estimating problem discovery rates.

After discussion with Dr. Roger Day, we arrived at two methods for determining the needed sample size: simulation and heuristics. To ensure adequate statistical power, I include both (see \ref{poweranalysis}). While it is plain to see the number used in the analysis were made up, the important determination is not the values used but the sensitivity of the result to changes in assumption. Other assumptions, by way of parameter settings, are detailed below:

\begin{itemize}
\item{Test statistic: for task completion time and error rates the sample means from each method are used to determine significance}
\item{Sources of variance in task completion time: built into the model are assumptions about case, method, person, and measurement (or unsystematic) variance}
\item{Model distributions: I use the normal distribution, centered at the task completion mean for each group and the Poison distribution with lambda equal to mean error rates for each group}
\item{Effect size: the measured difference in task completion time and error rate across methods}
\end{itemize}

After varying the parameters and running the experiment 2,000 times for each setting, I determined the required effect size for statistically significance in values of $n < 40$ and power $\ge 0.80$ is between 15--17\%. This translates into a two to three minute time savings for a mean task completion time of 17 minutes.

\begin{figure}[h!t]
\begin{center}
\includegraphics[width=\textwidth]{pwranal1.png}
\end{center}
\caption{Plot of null and alternative distributions; the rejection region and the power region are highlighted \cite{Ogle:2012qf}.}\label{pwranal} 
\end{figure}

\noindent Performing a two-way ANOVA on the simulated data yields: 
\begin{verbatim}
                  Df Sum Sq Mean Sq F value  Pr(>F)   Method             1   19.8   19.81   1.923 0.18454   Case               1    0.0    0.02   0.002 0.96339   Person            17  631.7   37.16   3.607 0.00682 **Residuals         16  164.8   10.30                   ---Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 
\end{verbatim}
\noindent The summary of ANOVA shows the greatest source of variance is the person followed by the method, which is consistent with the model parameters. Using the heuristic inspection method from the \texttt{NCStats} package, we can see a value of $18 \le n \le 20$ will provide power above 0.80 for liberal assumptions of variance (Figure \ref{pwranal}). An analysis similar to Turner (2006) could be performed on error rates. Given the even smaller amount of \textit{a priori} knowledge of expected error rates and the use of Poisson sampling, the results of such analysis would be less powerful than the results of task completion simulation.



\section{Proposed Timeline}

\begin{timeline}{4.2in}(5,265)
\optrule
  \item[10]{April}{Initial proposal}
  \item[14]{April}{Begin thesis}
  \item[18]{May}{Begin development}
  \item[52]{June}{Begin contextual inquiry}
  \item[92]{August}{Complete contextual inquiry}
  \item[102]{August}{Model building}
  \item[102]{August}{Begin sketches and paper prototypes}
  \item[112]{September}{Screen design and wireframe revision}
  \item[112]{September}{Preliminary expert review}
  \item[132]{September}{Complete preliminary expert review}
  \item[160]{September}{Complete proposal}
  \item[163]{September}{Complete functional specification}
  \item[170]{October}{Begin principal development}
  \item[195]{October}{Second round of expert review}
  \item[202]{November}{Begin design iteration}
  \item[226]{December}{Third round of expert review}
  \item[230]{December}{Design polish}
  \item[250]{January}{Complete interactive prototype}
  \item[257]{January}{Begin evaluation}
\end{timeline}%% Needed comment

\noindent Because I will be living in Virginia after January 2013, it is hard to predict the exact evaluation schedule. My aim is to complete the evaluation by the spring and complete the thesis by the summer.

\vspace{20pt}

\noindent \textit{Acknowledgements} I would like to thank Gerald Douglas, Harry Hochheiser, Titus Schleyer, and Roger Day for their invaluable input. This research made possible by the National Library of Medicine through grant 2T15LM007059-26.
\newpage

\footnotesize{
\bibliography{Master}}
\newpage

\addappheadtotoc
\appendix
%\renewcommand\thesection{Appendix \Alph{section}}


\section{CPR Screenshots}
\label{SS}
\subsection{Dentrix}
\label{dentrixplain}

\begin{figure}[h]
\begin{center}
\includegraphics[width=\textwidth]{dentrixss1.png}
\end{center}
\caption{Screenshot of Dentrix's G4 user interface.}
\end{figure}

\newpage

\subsection{Dentrix user mouse tracking data}
\label{dentrixusabil}
\begin{figure}[h]
\begin{center}
\includegraphics[width=\textwidth]{dentrixuse.png}
\end{center}
\caption{Screenshot showing a user’s actions while trying to record tooth no. 28 as missing while using the Dentrix v10.0.36.0. The correct sequence consists of the following left mouse clicks: “tooth no. 28,” “Conditions,” “Missing tooth,” “OK” and “EX”\cite{Thyvalikakath2008A-usability-eva}.}
\end{figure}

\newpage
\subsection{EagleSoft}
\label{ES}
\begin{figure}[h]
\begin{center}
\includegraphics[width=\textwidth]{esss.png}
\end{center}
\caption{Screenshot of EagleSoft's v16.0 user interface.}
\end{figure}

\newpage

\subsection{Screen controls}
\label{controls}
\begin{figure}[h]
\begin{center}
\includegraphics[width=\textwidth]{controls.png}
\end{center}
\caption{Charting icons for hard-tissue findings and procedures in Dentrix v 10.0.36.0, EagleSoft v 10.0, SoftDent v 10.0.2, and PracticeWorks v 5.0.2 \cite{Thyvalikakath2007Heuristic-evalu}. Expert review found heuristics such as Consistency and Standards and Match Between System and the Real World were often violated by hard tissue controls. One expert found PracticeWorks icons to be ambiguous. One common theme was the lack of reliance on operating system convention to help the user with recognition rather than recall.}\end{figure}


\newpage
\subsection{Tablet prototype}
\label{Prototype}

\begin{figure}[h!t]
\begin{center}
\includegraphics[width=\textwidth]{wireframe.png}
\end{center}
\caption{Mockup for tablet-based prototype. Much of the design inspiration comes from the two usability studies of dental CPRs. Button controls large enough for fingers and taken from the \texttt{StdUILibrary} within Xcode. Many other conventions like tap to select and swipe-based navigation also leverage user familiarity with iOS devices. Navigation along the top is couched in the concept of the initial exam and allows users to customize the content and sequence of data capture. And the ability to programmatically render diagnoses and treatments based on problems identified allow more efficient data entry.}
\end{figure}

\newpage
\section{Artifact Model}
\label{artifact}
\begin{figure}[h!b]
\begin{center}
\includegraphics[width=\textwidth]{artifactmodel.png}
\end{center}
\caption{Artifact model generated from common paper-based treatment planning forms}
\end{figure}
\newpage

\section{Physical Models}
\label{physical}
\subsection{Rear-delivery}

\begin{figure}[h!t]
\begin{center}
\includegraphics[width=\textwidth]{phymodel1.png}
\end{center}
\caption{Rear-delivery physical model for a right-handed operator.}
\end{figure}

\subsection{Side-delivery}
\begin{figure}[h!]
\begin{center}
\includegraphics[width=\textwidth]{phymodel2.png}
\end{center}
\caption{Side-delivery physical model for a right-handed operator.}
\end{figure}

\subsection{Chair-delivery}
\begin{figure}[h!]
\begin{center}
\includegraphics[width=\textwidth]{phymodel3.png}
\end{center}
\caption{Chair-delivery physical model for a right-handed operator.}
\end{figure}

\section{Power Analysis}
\label{poweranalysis}
\begin{verbatim}
# Begin model parameters
Nsubjects = 18
# Mean task completion time for H0 and HA
method_effect= c(A=18, B=15)
# Lambda mean error rates for H0 and HA;
lambda = c(A=1, B=0.5)

# Begin sources of variance
method_sd = c(A=5, B=4)
person_effect = rnorm(Nsubjects, 0, 4)
# KEY ASSUMPTION: variance due to case?
case_effect = c(1,0)
# All other sources of variance
unsystematic_sd = 3
# End model parameters

## Construct data frame(person, case, method); no explicit use of as.factor 
for subjects and case due to needing to select only a fraction of factorial
(tempOK).
temp = expand.grid(1:Nsubjects, 1:2, c("A","B"))
names(temp) = c("Person","Case","Method")

# Select fraction of total comb
tempOK = temp$Person + temp$Case + match(temp$Method, unique(temp$Method))
temp = temp[ (tempOK %% 2)==0 , ]

# Generate model task completion times
temp$Time = case_effect[temp$Case] + person_effect[temp$Person] + 
  method_effect[temp$Method] + rnorm(1, 0, method_sd[temp$Method]) +
  rnorm(nrow(temp), 0, unsystematic_sd)

# Generate error rates
temp$Error = rpois(n=Nsubjects, lambda=lambda)

# Clean up and assign temp to dframe
dframe = temp[with(temp, order(Person, Method)), ]
row.names(dframe) = 1:nrow(temp)

# Simulate experiment, looping over dframe H0 and HA xNREPS
NREPS = 2000
Nsubjects = 18

pValues = sapply(1:NREPS, function(ignoreMe) {
  dframe = expand.grid(as.factor(1:2), c("A","B"), as.factor(1:Nsubjects))
  names(dframe) = c("Case","Method","Person")
  dframeOK = as.numeric(dframe$Person) + as.numeric(dframe$Case) + 
    as.numeric(match(dframe$Method, unique(dframe$Method)))
  dframe = dframe[ (dframeOK %% 2)==0 , ]
  dframe$Time = case_effect[dframe$Case] + person_effect[dframe$Person] + 
    method_effect[dframe$Method] + rnorm(1, 0, method_sd[dframe$Method]) + 
    rnorm(nrow(dframe), 0, unsystematic_sd)
  model <- glm(Time ~ Method + Case + as.factor(Person), data=dframe)
  summary(model)$coef["MethodB", "Pr(>|t|)"]
}
)
summary(pValues)
mean(pValues < 0.05)
\end{verbatim}


\end{document}	 	       